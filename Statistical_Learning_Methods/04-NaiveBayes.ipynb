{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3298b2-cd7e-45a3-bc8d-2b85f24a6617",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2f3b1-02b1-4cb0-8ce5-61365b6307cd",
   "metadata": {},
   "source": [
    "机器学习中的逻辑回归、决策树等模型属于**判别方法**，即直接学习标签$y$与特征$X$之间的关系，得到决策函数$y = f(X)$或条件分布$P(Y|X)$；但朴素贝叶斯数据**生成方法**，它直接找标签与特征的联合分布$P(X, Y)$，然后通过\n",
    "$$\n",
    "P(Y|X) = \\dfrac{P(X, Y)}{P(X)}\n",
    "$$\n",
    "计算得出判定结果。\n",
    "\n",
    "其中各部分含义为\n",
    "\n",
    "- $P(Y|X)$：后验概率，已知样本特征，样本属于类别$Y$的概率（最终计算目标）；\n",
    "\n",
    "- $P(Y)$：先验概率，在不考虑任何特征的情况下，样本$Y$出现的占比；\n",
    "\n",
    "- $P(X|Y)$：似然概率，已知类别$Y$的前提下，样本出现特征$X$的概率；\n",
    "\n",
    "**朴素贝叶斯的核心假设——给定类别$Y$的条件下，样本的各特征之间独立，即**\n",
    "$$\n",
    "P(X|Y) = P(X_1|Y)\\cdots P(X_2|Y) \\cdots P(X_n|Y)\n",
    "$$\n",
    "\n",
    "- $P(X)$：特征$X$本身出现的概率，固定值，用于归一化；\n",
    "\n",
    "\n",
    "朴素贝叶斯算法的核心思想是通过考虑特征概率来预测分类，即对于给出的待分类样本，求解在此样本出现的条件下各个类别出现的概率，哪个最大，就认为此待分类样本属于哪个类别。\n",
    "\n",
    "设$X=\\{a_1,a_2,\\cdots,a_n\\}$为一个待分类项，每个$a_i$为$x$的一个特征属性，且特征属性之间相互独立。设$C=\\{y_1, y_2, \\cdots,y_n\\}$为一个类别集合，计算\n",
    "$$\n",
    "P(y_k|X) = \\text{max}\\{ P(y_1|X), P(y_2|X), \\cdots, P(y_n|X) \\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(y_k|X) = \\dfrac{P(X|y_i)P(y_i)}{P(X)}\n",
    "$$\n",
    "分母是固定的常数，只需考虑分子\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(X|y_i)P(y_i) &= P(a_1|y_i)P(a_2|y_2)\\cdots P(a_n|y_i)P(y_i)\\\\\n",
    "&= P(y_i)\\prod_{j=1}^n{P(a_j|y_i)}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "其中$n$是一个样本的特征数，可以推出\n",
    "$$\n",
    "P(X|y_i) = \\prod_{j=1}^n{P(a_j|y_i)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80a5921-64e2-46e1-ae14-35a8f3ba5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd7b4aa-b64e-481e-b1a5-f4d4b61e4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df[\"label\"] = iris.target\n",
    "df.columns = [\n",
    "    \"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"label\"\n",
    "]\n",
    "\n",
    "data = np.array(df.iloc[:100, :])\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf21084-f6ed-4dfe-aced-e3b782d273bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    @staticmethod\n",
    "    def mean(X):\n",
    "        return sum(X) / float(len(X))\n",
    "\n",
    "    def stdev(self, X):\n",
    "        avg = self.mean(X)\n",
    "        return math.sqrt(sum([pow(x - avg, 2) for x in X]) / float(len(X)))\n",
    "\n",
    "    def gaussian_probability(self, x, mean, stdev):\n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) /\n",
    "                              (2 * math.pow(stdev, 2))))\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "    def summarize(self, train_data):\n",
    "        summaries = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)]\n",
    "        return summaries\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        labels = list(set(y))\n",
    "        data = {label: [] for label in labels}\n",
    "        for f, label in zip(X, y):\n",
    "            data[label].append(f)\n",
    "        self.model = {\n",
    "            label: self.summarize(value)\n",
    "            for label, value in data.items()\n",
    "        }\n",
    "        return \"GaussianNB Train\"\n",
    "\n",
    "    def calculate_probabilities(self, input_data):\n",
    "        probabilities = {}\n",
    "        for label, value in self.model.items():\n",
    "            probabilities[label] = 1\n",
    "            for i in range(len(value)):\n",
    "                mean, stdev = value[i]\n",
    "                probabilities[label] *= self.gaussian_probability(\n",
    "                    input_data[i], mean, stdev)\n",
    "        return probabilities\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        label = sorted(\n",
    "            self.calculate_probabilities(X_test).items(),\n",
    "            key=lambda x: x[-1])[-1][0]\n",
    "        return label\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0\n",
    "        for X, y in zip(X_test, y_test):\n",
    "            label = self.predict(X)\n",
    "            if label == y:\n",
    "                right += 1\n",
    "\n",
    "        return right / float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6add5acd-2aa2-4284-a6b9-ad811a1568aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f09e57-85b4-4100-b16b-723148833601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GaussianNB Train'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f14793ce-b440-4ea9-83d0-6e230d7c6b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([4.4,  3.2,  1.3,  0.2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be0a4e",
   "metadata": {},
   "source": [
    "## scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9c3714-9fd2-477f-b1df-c935c95da4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d585f66-ec31-4082-8c62-59a1dfb36f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "# clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b30534a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4.4, 3.2, 1.3, 0.2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
